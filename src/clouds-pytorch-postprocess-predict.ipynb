{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade efficientnet-pytorch\n",
    "!pip install --upgrade pretrainedmodels\n",
    "!pip install git+https://github.com/qubvel/segmentation_models.pytorch\n",
    "!pip install git+https://github.com/michal-nahlik/FastFCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import albumentations as albu\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pretrainedmodels\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from segmentation_models_pytorch import Unet, FPN, PSPNet\n",
    "from encoding.models.encnet import EncNet\n",
    "from encoding.models.deeplabv3 import DeepLabV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2019\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, list_IDs=None, rles_df = None, data_folder = None, transforms=None,\n",
    "                dim=(1400, 2100), reshape=(320, 480)):\n",
    "        self.list_IDs = list_IDs\n",
    "        self.rles_df = rles_df\n",
    "        self.data_folder = data_folder\n",
    "        self.transforms = transforms\n",
    "        self.dim = dim\n",
    "        self.reshape = reshape\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ID = self.list_IDs.iloc[idx]\n",
    "        img_path = self.data_folder + ID\n",
    "        img = self.load_rgb(img_path)\n",
    "        mask = None\n",
    "        \n",
    "        if self.reshape is not None:\n",
    "            img = np_resize(img, self.reshape)\n",
    "            \n",
    "        if self.rles_df is not None:\n",
    "            image_df = self.rles_df[self.rles_df['ImageId'] == ID]\n",
    "            rles = image_df['EncodedPixels'].values\n",
    "            \n",
    "            if self.reshape is not None:\n",
    "                mask = build_masks(rles, input_shape=self.dim, reshape=self.reshape)\n",
    "            else:\n",
    "                mask = build_masks(rles, input_shape=self.dim)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            augmented = self.transforms(image=img, mask=mask)\n",
    "            img  = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"]\n",
    "        \n",
    "        if mask is None:\n",
    "            return ID, img, []\n",
    "        else:\n",
    "            return ID, img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "    \n",
    "    def load_rgb(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def dice(img1, img2):\n",
    "    img1 = img1 > 0.5\n",
    "    img2 = img2 > 0.5\n",
    "    img1 = np.asarray(img1).astype(np.bool)\n",
    "    img2 = np.asarray(img2).astype(np.bool)\n",
    "\n",
    "    intersection = np.logical_and(img1, img2)\n",
    "\n",
    "    return 2.0 * intersection.sum() / (img1.sum() + img2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rle, mask, image manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_resize(img, input_shape):\n",
    "    \"\"\"\n",
    "    Reshape a numpy array, which is input_shape=(height, width), \n",
    "    as opposed to input_shape=(width, height) for cv2\n",
    "    \"\"\"\n",
    "    height, width = input_shape\n",
    "    return cv2.resize(img, (width, height))\n",
    "\n",
    "def mask2rle(img):\n",
    "    \"\"\"\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    \"\"\"\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(rle, input_shape):\n",
    "    width, height = input_shape[:2]\n",
    "    \n",
    "    mask= np.zeros( width*height ).astype(np.uint8)\n",
    "    \n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        mask[int(start):int(start+lengths[index])] = 1\n",
    "        current_position += lengths[index]\n",
    "        \n",
    "    return mask.reshape(height, width).T\n",
    "\n",
    "def build_masks(rles, input_shape, reshape=None):\n",
    "    depth = len(rles)\n",
    "    if reshape is None:\n",
    "        masks = np.zeros((*input_shape, depth))\n",
    "    else:\n",
    "        masks = np.zeros((*reshape, depth))\n",
    "    \n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            if reshape is None:\n",
    "                masks[:, :, i] = rle2mask(rle, input_shape)\n",
    "            else:\n",
    "                mask = rle2mask(rle, input_shape)\n",
    "                reshaped_mask = np_resize(mask, reshape)\n",
    "                masks[:, :, i] = reshaped_mask\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def build_rles(masks, thrs=None, reshape=None):\n",
    "    width, height, depth = masks.shape\n",
    "    \n",
    "    rles = []\n",
    "    \n",
    "    for i in range(depth):\n",
    "        mask = masks[:, :, i]\n",
    "        if thrs is not None:\n",
    "            mask = mask > thrs[i]\n",
    "        \n",
    "        if reshape:\n",
    "            mask = mask.astype(np.float32)\n",
    "            mask = np_resize(mask, reshape).astype(np.int64)\n",
    "        \n",
    "        rle = mask2rle(mask)\n",
    "        rles.append(rle)\n",
    "        \n",
    "    return rles\n",
    "\n",
    "def rle_area(rle):\n",
    "    try:\n",
    "        array = np.asarray([int(x) for x in rle.split()])\n",
    "        lengths = array[1::2]\n",
    "        return np.sum(lengths)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post processing\n",
    "Remove small masks and draw convex hull mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ratthachat/cloud-convexhull-polygon-postprocessing-no-gpu\n",
    "def draw_convex_hull(mask, mode='convex'):\n",
    "    \n",
    "    img = np.zeros(mask.shape)\n",
    "    contours, hier = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for c in contours:\n",
    "        if mode=='rect': # simple rectangle\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 255), -1)\n",
    "        if mode=='convex': # minimum convex hull\n",
    "            hull = cv2.convexHull(c)\n",
    "            cv2.drawContours(img, [hull], 0, (255, 255, 255),-1)\n",
    "        else: # minimum area rectangle\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            cv2.drawContours(img, [box], 0, (255, 255, 255),-1)\n",
    "    return img/255.\n",
    "\n",
    "\n",
    "def post_process(probability, threshold, min_size):\n",
    "    \"\"\"\n",
    "    This is slightly different from other kernels as we draw convex hull here itself.\n",
    "    Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored\n",
    "    \"\"\"\n",
    "    # don't remember where I saw it\n",
    "    mask = (cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1])\n",
    "    mask = draw_convex_hull(mask.astype(np.uint8))\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((350, 525), np.float32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = component == c\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from newer version of albumentations, changed apply_to_mask transpose so the multilayer mask works\n",
    "from albumentations.core.transforms_interface import BasicTransform\n",
    "\n",
    "class ToTensorV2(BasicTransform):\n",
    "    \"\"\"Convert image and mask to `torch.Tensor`.\"\"\"\n",
    "\n",
    "    def __init__(self, always_apply=True, p=1.0):\n",
    "        super(ToTensorV2, self).__init__(always_apply=always_apply, p=p)\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return {\"image\": self.apply, \"mask\": self.apply_to_mask}\n",
    "\n",
    "    def apply(self, img, **params):\n",
    "        return torch.from_numpy(img.transpose(2, 0, 1))\n",
    "\n",
    "    def apply_to_mask(self, mask, **params):\n",
    "        return torch.from_numpy(mask.transpose(2, 0, 1))\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return []\n",
    "\n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, VerticalFlip, HorizontalFlip, ShiftScaleRotate, CLAHE, HueSaturationValue,\n",
    "    RandomBrightness, RandomContrast, RandomGamma,OneOf,\n",
    "    ToFloat, ShiftScaleRotate,GridDistortion, ElasticTransform, JpegCompression, HueSaturationValue,\n",
    "    RGBShift, RandomBrightness, RandomContrast, Blur, MotionBlur, MedianBlur, GaussNoise,CenterCrop,\n",
    "    IAAAdditiveGaussianNoise,GaussNoise,OpticalDistortion,RandomSizedCrop\n",
    ")\n",
    "\n",
    "AUGMENTATIONS_TEST = Compose([\n",
    "    ToFloat(max_value=1),\n",
    "    ToTensorV2()\n",
    "],p=1)\n",
    "\n",
    "AUGMENTATIONS_TEST_TTA_1 = Compose([\n",
    "    HorizontalFlip(p=1),\n",
    "    ToFloat(max_value=1),\n",
    "    ToTensorV2()\n",
    "],p=1)\n",
    "\n",
    "AUGMENTATIONS_TEST_TTA_2 = Compose([\n",
    "    VerticalFlip(p=1),\n",
    "    ToFloat(max_value=1),\n",
    "    ToTensorV2()\n",
    "],p=1)\n",
    "\n",
    "AUGMENTATIONS_TEST_TTA_3 = Compose([\n",
    "    HorizontalFlip(p=1),\n",
    "    VerticalFlip(p=1),\n",
    "    ToFloat(max_value=1),\n",
    "    ToTensorV2()\n",
    "],p=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Fish\", \"Flower\", \"Gravel\", \"Sugar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../input/understanding_cloud_organization/'\n",
    "path_train = path + 'train_images/'\n",
    "path_test = path + 'test_images/'\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(path + 'train.csv')\n",
    "train_df['ImageId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "train_df['ClassId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "train_df['MaskArea'] = train_df['EncodedPixels'].apply(lambda x: rle_area(x))\n",
    "train_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_count_df = train_df.groupby('ImageId').agg({'hasMask' : np.sum, 'MaskArea': list}).reset_index()\n",
    "print(np.shape(mask_count_df))\n",
    "mask_count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split based on mask area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_areas = np.stack(mask_count_df['MaskArea'].values)\n",
    "mask_areas = mask_areas > 0\n",
    "train_idx, val_idx = train_test_split(mask_count_df['ImageId'], stratify=mask_areas, random_state=seed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask_areas = np.stack(mask_count_df.iloc[train_idx.index]['MaskArea'].values)\n",
    "val_mask_areas   = np.stack(mask_count_df.iloc[val_idx.index]['MaskArea'].values)\n",
    "\n",
    "f, ax = plt.subplots(nrows=2, ncols=4, figsize=(20,8))\n",
    "for i in range(0,4):\n",
    "    sns.distplot(train_mask_areas[:,i], ax=ax[0,i]).set_title(class_names[i])\n",
    "    sns.distplot(val_mask_areas[:,i], ax=ax[1,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set size: {}'.format(len(train_idx)))\n",
    "print('Validation set size: {}'.format(len(val_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset and dataloader\n",
    "num_workers = 4\n",
    "bs = 8\n",
    "\n",
    "valid_dataset = CloudDataset(list_IDs = val_idx,   rles_df=train_df, data_folder = path_train, transforms=AUGMENTATIONS_TEST)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=bs, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best post processing params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, loader, limit, get_masks=True):\n",
    "    valid_masks = []\n",
    "    probabilities = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for IDs, data, target in tqdm(loader):\n",
    "            if train_on_gpu:\n",
    "                data = data.to(device, dtype=torch.float)\n",
    "\n",
    "            output = model(data)\n",
    "            # EncNet has 3 outputs\n",
    "            if (len(output) == 3):\n",
    "                output = output[0].cpu().detach().numpy().astype(np.float16)\n",
    "            # DeepLabV3 has 2 outputs\n",
    "            elif (len(output) == 2):\n",
    "                output = output[0].cpu().detach().numpy().astype(np.float16)\n",
    "            else:\n",
    "                output = output.cpu().detach().numpy().astype(np.float16)\n",
    "\n",
    "            probabilities.extend(output)\n",
    "            \n",
    "            if get_masks:\n",
    "                target = target.numpy().astype(np.uint8)\n",
    "                valid_masks.extend(target)\n",
    "\n",
    "            if np.shape(probabilities)[0] >= limit:\n",
    "                break\n",
    "                \n",
    "    return valid_masks, probabilities\n",
    "\n",
    "\n",
    "def predict_with_ttas(model, loader, limit=200):\n",
    "    loader.dataset.transforms=AUGMENTATIONS_TEST\n",
    "    valid_masks, probabilities = get_predictions(model, loader, limit)\n",
    "    \n",
    "    #valid_loader.dataset.transforms=AUGMENTATIONS_TEST_TTA_1\n",
    "    #_, tmp = get_predictions(model, valid_loader, limit, False)\n",
    "    #probabilities = np.sum([probabilities, tmp], axis=0)\n",
    "    \n",
    "    #valid_loader.dataset.transforms=AUGMENTATIONS_TEST_TTA_2\n",
    "    #_, tmp = get_predictions(model, valid_loader, False)\n",
    "    #probabilities = np.sum([probabilities, tmp], axis=0)\n",
    "\n",
    "    #valid_loader.dataset.transforms=AUGMENTATIONS_TEST_TTA_3\n",
    "    #_, tmp = get_predictions(model, valid_loader, False)\n",
    "    #probabilities = np.sum([probabilities, tmp], axis=0)\n",
    "    \n",
    "    return valid_masks, probabilities\n",
    "\n",
    "\n",
    "def load_model(path_model, device):\n",
    "    model = torch.load(path_model)\n",
    "    if train_on_gpu:\n",
    "        model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model_and_predict(path_model, device):\n",
    "    model = load_model(path_model, device)\n",
    "    return predict_with_ttas(model, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on validation set\n",
    "Creates models and predicts on 200 images from validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPN with EfficientB4 encoder\n",
    "valid_masks, probabilities = load_model_and_predict('../input/clouds-pytorch-fpn/fpn_clouds_dice.pth', device)\n",
    "prob_sum = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net with EfficientB4 encoder\n",
    "valid_masks, probabilities = load_model_and_predict('../input/clouds-pytorch-unet/unet_clouds_dice.pth', device)\n",
    "prob_sum = np.sum([probabilities, prob_sum], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EncNet with resnet50 encoder\n",
    "valid_masks, probabilities = load_model_and_predict('../input/clouds-pytorch-encnet/encnet_clouds_dice.pth', device)\n",
    "prob_sum = np.sum([probabilities, prob_sum], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepLabV3 with resnet50 encoder\n",
    "valid_masks, probabilities = load_model_and_predict('../input/clouds-pytorch-deeplabv3/deeplabv3_clouds_dice.pth', device)\n",
    "prob_sum = np.sum([probabilities, prob_sum], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = prob_sum / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params(valid_masks, probabilities):\n",
    "    class_params = {}\n",
    "\n",
    "    for class_id in range(4):\n",
    "        print(class_id)\n",
    "        attempts = []\n",
    "        for t in range(0, 100, 10):\n",
    "            t /= 100\n",
    "            for ms in range(1000,15000, 1000):\n",
    "                masks = []\n",
    "                for i in range(len(probabilities)):\n",
    "                    probability = np.float32(probabilities[i][class_id][:][:])\n",
    "                    probability = np_resize(probability, (350, 525))\n",
    "                    predict, num_predict = post_process(sigmoid(probability), t, ms)\n",
    "                    masks.append(predict)\n",
    "\n",
    "                d = []\n",
    "                for i in range(len(masks)):\n",
    "                    target = valid_masks[i][class_id][:][:]\n",
    "                    target = np_resize(target, (350, 525))\n",
    "                    mask = masks[i][:][:]\n",
    "\n",
    "                    if (target.sum() == 0) & (mask.sum() == 0):\n",
    "                        d.append(1)\n",
    "                    else:\n",
    "                        d.append(dice(target, mask))\n",
    "\n",
    "                attempts.append((t, ms, np.mean(d)))\n",
    "\n",
    "        attempts_df = pd.DataFrame(attempts, columns=['threshold', 'size', 'dice'])\n",
    "        attempts_df = attempts_df.sort_values('dice', ascending=False)\n",
    "        print(attempts_df.head())\n",
    "        best_threshold = attempts_df['threshold'].values[0]\n",
    "        best_size = attempts_df['size'].values[0]\n",
    "\n",
    "        class_params[class_id] = (best_threshold, best_size)\n",
    "        \n",
    "        sns.lineplot(x='threshold', y='dice', hue='size', data=attempts_df)\n",
    "        plt.title('Threshold and min size vs dice for one of the classes')\n",
    "        plt.show()\n",
    "        \n",
    "    return class_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_params = get_best_params(valid_masks, probabilities)\n",
    "class_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2):    \n",
    "    f, ax = plt.subplots(ncols=4, nrows=4, figsize=(20,8))\n",
    "\n",
    "    ax[0][0].set_ylabel('Output')\n",
    "    ax[1][0].set_ylabel('Threshold only')\n",
    "    ax[2][0].set_ylabel('Post process')\n",
    "    ax[3][0].set_ylabel('Target')\n",
    "    \n",
    "    for j in range(0, 4):\n",
    "        p = np.float32(probabilities[i][j][:][:])\n",
    "        p = np_resize(p, (350, 525))\n",
    "        pp, num = post_process(sigmoid(p), class_params[j][0], class_params[j][1])\n",
    "        \n",
    "        ax[0][j].set_title(class_names[j])\n",
    "        ax[0][j].imshow(p)\n",
    "        ax[1][j].imshow(p > class_params[j][0])\n",
    "        ax[2][j].imshow(pp)\n",
    "        \n",
    "        ax[3][j].imshow(np.float32(valid_masks[i][j][:][:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "del valid_loader, valid_dataset, probabilities, valid_masks, prob_sum\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = os.listdir(path_test)\n",
    "test_idx = pd.DataFrame(test_idx, columns={'ImageId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "bs = 8\n",
    "\n",
    "test_dataset = CloudDataset(list_IDs = test_idx['ImageId'], rles_df=None, data_folder=path_test, transforms=AUGMENTATIONS_TEST)\n",
    "test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPN with EfficientB4 encoder\n",
    "model1 = load_model('../input/clouds-pytorch-fpn/fpn_clouds_dice.pth', device)\n",
    "# U-Net with EfficientB4 encoder\n",
    "model2 = load_model('../input/clouds-pytorch-unet/unet_clouds_dice.pth', device)\n",
    "# EncNet with resnet50 encoder\n",
    "model3 = load_model('../input/clouds-pytorch-encnet/encnet_clouds_dice.pth', device)\n",
    "# DeepLabV3 with resnet50 encoder\n",
    "model4 = load_model('../input/clouds-pytorch-deeplabv3/deeplabv3_clouds_dice.pth', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict, post process and create rles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_labels = []\n",
    "rles = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for IDs, data, _ in tqdm(test_loader):\n",
    "        if train_on_gpu:\n",
    "            data = data.to(device, dtype=torch.float)\n",
    "\n",
    "        output1 = model1(data)\n",
    "        output1 = output1.cpu().detach().numpy()\n",
    "        \n",
    "        output2 = model2(data)\n",
    "        output2 = output2.cpu().detach().numpy()\n",
    "        \n",
    "        output3 = model3(data)[0]\n",
    "        output3 = output3.cpu().detach().numpy()\n",
    "        \n",
    "        output4 = model4(data)[0]\n",
    "        output4 = output4.cpu().detach().numpy()\n",
    "        \n",
    "        output = output1 + output2 + output3 + output4\n",
    "        output = output / 4\n",
    "        \n",
    "        for i in range(0, len(IDs)):\n",
    "            for j in range(0, 4):\n",
    "                p = np.float32(output[i][j][:][:])\n",
    "                p = np_resize(p, (350, 525))\n",
    "                pp, num = post_process(sigmoid(p), class_params[j][0], class_params[j][1])\n",
    "                rles.append(mask2rle(pp))\n",
    "                image_labels.append(IDs[i] + '_' + class_names[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and write submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'Image_Label': image_labels, 'EncodedPixels': rles})\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/understanding_cloud_organization/sample_submission.csv')\n",
    "print('Sample submission lenght: {} \\nTest submission length: {}'.format(len(test_df), len(sub))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('clouds_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
